[
  {
    "objectID": "publication.html",
    "href": "publication.html",
    "title": "Publication",
    "section": "",
    "text": "2022\nParameter estimation and model-based clustering with spherical normal distribution on the unit hypersphere KY and Changhee Suh.  Computational Statistics & Data Analysis (2022).\n        \n        arXiv\n     \n        \n        Code\n     \n        \n        Publisher's Site\n    \n Learning Subspaces of Different Dimensions Brian St. Thomas, KY, Lizhen Lin, Lek-Heng Lim, and Sayan Mukherjee.  Journal of Computational and Graphical Statistics (2022).\n        \n        arXiv\n     \n        \n        Code\n     \n        \n        Publisher's Site\n    \n2021\nRe-visiting Riemannian geometry of symmetric positive definite matrices for the analysis of functional connectivity KY and Hae-Jeong Park.  NeuroImage (2021).\n        \n        Code\n     \n        \n        Publisher's Site\n    \n2020\nData transforming augmentation for heteroscedastic models Hyungsuk Tak, KY, Sujit K. Ghosh, Bingyue Su, and Joseph Kelly.  Journal of Computational and Graphical Statistics (2020).\n        \n        arXiv\n     \n        \n        Publisher's Site\n    \n2019\nVolume change pattern of decompression of mandibular odontogenic keratocyst Jin Hoo Park, Eun-Jung Kwak, KY, Young-Soo Jung, and Hwi-Dong Jung.  Maxillofacial Plastic and Reconstructive Surgery (2019).\n        \n        Publisher's Site\n    \n2016\nVision-based detection of loosened bolts using the Hough transform and support vector machines Young-Jin Cha, KY, and Wooram Choi.  Automation in Construction (2016).\n        \n        Publisher's Site\n    \nWork in Progress\nRdimtools: An R package for Dimension Reduction and Intrinsic Dimension Estimation KY and Dennis Shung  Submitted to Software Impacts.\n        \n        arXiv\n    \nArchived Preprint\nNetwork Distance Based on Laplacian Flows on Graphs Dianbin Bao, KY, and Lizhen Lin (2018).\n        \n        arXiv\n     \n        \n        Code"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Kisung You",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n\n\n\n\n  \n\n\n\n\nRodrigues’ formula for the Legendre polynomials\n\n\n\n\n\n\n\nnotes\n\n\ncalculus\n\n\n\n\n\n\n\n\n\n\n\nAug 10, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonte Carlo computation of \\(L_p\\) distance between two densities on the unit hypersphere\n\n\n\n\n\n\n\nnotes\n\n\ngeometric statistics\n\n\ncomputation\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kisung You",
    "section": "",
    "text": "I am a postdoctoral associate in the Department of Internal Medicine at Yale School of Medicine working with Prof. Dennis Shung. My research focuses on the use of mathematical tools from statistics, geometry, and topology in developing novel methods to answer abstruse scientific questions. I am also deeply interested in high-performance computing and statistical software development to democratize methodological innovations for practitioners.\n\n\n\n\n\nUniversity of Notre Dame\nPhD in Statistics\n Advisors: Lizhen Lin, Ick Hoon Jin\n Thesis: Topics in Geometric and Topological Data Analysis\n\n\nNotre Dame, IN\nAugust 2021\n\n\n\nYonsei University\nMS in Applied Mathematics\n BBA in Business Administration\nBS in Mathematics\n\nSeoul, South Korea\nAugust 2015\n August 2013"
  },
  {
    "objectID": "posts/note002-rodrigues-formula/index.html",
    "href": "posts/note002-rodrigues-formula/index.html",
    "title": "Rodrigues’ formula for the Legendre polynomials",
    "section": "",
    "text": "Approach\nI will proceed in two steps. Let \\(f_n (x) = (x^2 - 1)^n\\) then we first show that the \\(n\\)-th derivative of \\(f_n (x)\\) is a solution of Legendre equation. Then, we find a proper scaling factor of \\(1/ 2^n n!\\) to recover \\(P_n (x)\\) in line with a common constraint that \\(P_n (x) = 1\\) for all \\(n\\) when \\(x=1\\). For notational simplicity, we denote \\(g^{(n)}\\) for the \\(n\\)-th derivative of a function \\(g(x)\\), i.e,\n\\[\ng^{(n)} = \\frac{d^n}{dx^n} g(x).\n\\]\nBefore proceeding, we need (generalized) Leibniz’s rule. Suppose we have \\(n\\)-times differentiable functions \\(f(x)\\) and \\(g(x)\\), then\n\\[\n\\frac{d^n}{dx^n} f(x) g(x) = \\sum_{k=0}^n\n\\begin{pmatrix}\nn \\\\ k\n\\end{pmatrix}\nf^{(n-k)} (x) g^{(k)} (x) = \\sum_{k=0}^n \\frac{n!}{k! (n-k)!} f^{(n-k)} (x) g^{(k)} (x)\n\\tag{3}\\]\nwhere the choice of \\(f\\) and \\(g\\) can help in reducing the number of terms when there exists a polynomial term. For example, when \\(g(x) = x^2\\), \\(g^{(k)} = 0\\) for all \\(k \\geq 3\\).\n\n\nStep 1. \\(f_n^{(n)} (x)\\) is one solution.\nOur goal here is to show that \\(f_n^{(n)}(x)\\) is a solution for Equation 1. As a first step, let’s take derivative on \\(f_n (x)\\),\n\\[\n\\begin{align*}\n\\frac{d}{dx} f_n (x) &= 2 n (x^2  - 1)^{n-1} x \\\\\n&= 2nx (x^2 - 1)^{n-1}.\n\\end{align*}\n\\]\nBy multiplying \\((x^2 - 1)\\) both side of the above, we have\n\\[\n(x^2 - 1) \\frac{d}{dx} f_n (x)  = 2nx (x^2 - 1)^n.\n\\]\nNow, differentiate both sides \\((n+1)\\) times, which leads to\n\\[\n\\begin{align*}\n\\frac{d^{n+1}}{dx^{n+1}} \\left[ \\frac{d}{dx} f_n (x) \\right]  (x^2 -1)\n&= \\sum_{k=0}^{n+1}\n\\begin{pmatrix}\nn+1 \\\\ k\n\\end{pmatrix}\n\\left( \\frac{d}{dx} f_n (x) \\right)^{(n+1-k)} (x^2-1)^{(k)} \\\\\n&=\n\\begin{pmatrix}\nn+1 \\\\ 0\n\\end{pmatrix}\nf_n^{(n+2)} (x) (x^2-1) +\n\\begin{pmatrix}\nn+1 \\\\ 1\n\\end{pmatrix}\n2x f_n^{(n+1)}  (x) +\n\\begin{pmatrix}\nn+1 \\\\ 2\n\\end{pmatrix}\nf_n ^{(n)} (x) \\cdot 2 \\\\\n&= (x^2-1) f_n^{(n+2)} (x) + 2(n+1)x f_n^{(n+1)} (x) +\nn(n+1) f_n^{(n)} (x)\n\\end{align*}\n\\]\nfor the left-hand side. We also have that\n\\[\n\\begin{align*}\n\\frac{d^{n+1}}{dx^{n+1}} f_n(x) 2nx &=\n\\begin{pmatrix}\nn+1 \\\\ 0\n\\end{pmatrix}\nf_n^{(n+1)} (x) 2nx +\n\\begin{pmatrix}\nn+1 \\\\ 1\n\\end{pmatrix}\nf_n^{(n)} (x) 2n \\\\\n&= 2nx f_n^{(n+1)} (x) + 2n(n+1)f_n^{(n)}(x).\n\\end{align*}\n\\]\nTherefore, we have the following arrangement,\n\\[\n\\begin{equation*}\n    \\begin{gathered}\n    (x^2 - 1) f_n^{(n+2)} (x) + 2x(n+1)f_n^{(n+1)} (x) + n(n+1)f_n^{(n)} (x) =\n    2nx f_n^{(n+1)} (x) + 2n(n+1) f_n^{(n)} (x) \\\\\n    (x^2-1) f_n^{(n+2)} (x) + 2x f_n^{(n+1)}(x) - n(n+1)f_n^{(n)} (x) = 0 \\\\\n    (1- x^2) f_n^{(n+2)} (x) - 2x f_n^{(n+1)}(x) + n(n+1)f_n^{(n)} (x) = 0\n    \\end{gathered}\n\\end{equation*}\n\\]\nwhere the last line is in the form of Equation 1 so that we have \\(f_n^{(n)} (x)\\) as a solution.\n\n\nStep 2. Find a scaling factor.\nEven though \\(f_n^{(n)} (x)\\) as a solution, we have a requirement for the standard Legendre polynomial that \\(P_n (x)=1\\) for \\(x=1\\). Let us take a closer look at \\(f_n^{(n)}(x)\\) when evaluated at \\(x=1\\).\n\\[\n\\begin{align*}\nf_n^{(n)} (x) &= \\frac{d^n}{dx^n} (x^2-1)^n \\\\\n&= \\frac{d^n}{dx^n} (x+1)^n (x-1)^n \\\\\n&= \\sum_{k=0}^n \\begin{pmatrix}\nn \\\\ k\n\\end{pmatrix}\n\\left( (x+1)^n \\right)^{(k)} \\left( (x-1)^n \\right) ^{(n-k)} \\quad \\textrm{by the Leibniz's rule} \\\\\n&= \\sum_{k=0}^n \\begin{pmatrix}\nn \\\\ k\n\\end{pmatrix}\n\\frac{n!}{(n-k)!} (x+1)^{n-k} \\frac{n!}{k!} (x-1)^k \\qquad (*) \\\\\n&= n! \\sum_{k=0}^n \\begin{pmatrix}\nn \\\\ k\n\\end{pmatrix} \\frac{n!}{(n-k)! k!} (x+1)^{n-k} (x-1)^k \\\\\n&= n! \\sum_{k=0}^n \\begin{pmatrix}\nn \\\\ k\n\\end{pmatrix}^2 (x+1)^{n-k} (x-1)^k,\n\\end{align*}\n\\]\nSince we want to evaluate \\(f_n^{(n)} (x)\\) at \\(x=1\\), the last line of equations above tells us that all the terms but \\(k=0\\) become zero,\n\\[\n\\begin{equation*}\nf_n^{(n)} (x=1) = n! \\begin{pmatrix}\nn \\\\ 0\n\\end{pmatrix}^2 2^{n-0} = n! 2^n\n\\end{equation*}\n\\]\nwhich finally leads to define \\(P_n (x)\\) as\n\\[\nP_n (x) = \\frac{1}{n! 2^n}f_n^{(n)}(x)  = \\frac{1}{n! 2^n} \\frac{d^n}{dx^n} (x^2-1)^n\n\\]\nto fulfill the condition of \\(P_n (x) =1\\) for \\(x=1\\)."
  },
  {
    "objectID": "posts/note001-spherical-distance/index.html",
    "href": "posts/note001-spherical-distance/index.html",
    "title": "Monte Carlo computation of \\(L_p\\) distance between two densities on the unit hypersphere",
    "section": "",
    "text": "Computation\nImportance sampling requires a proposal density. The easiest choice is to use uniform density \\(u(x)\\) as an importance proposal since sampling from \\(u(x)\\) is trivial. First, take a random sample from standard normal distribution \\(x \\sim \\mathcal{N}(0,I)\\) in \\(\\mathbb{R}^{d+1}\\). Then, the rest is to take \\(L_2\\) normalization, i.e., \\(x \\leftarrow x / \\|x\\|_2\\), which makes a sampled vector to have a unit norm. Given the sample generation process, we have the following\n\\[\\begin{aligned}\nL_p (f,g)^p &= \\int_{\\mathbb{S}^d} |f(x)-g(x)|^p dx \\\\\n&= \\int_{\\mathbb{S}^d} \\frac{|f(x)-g(x)|^p}{u(x)} u(x)  dx \\\\\n&= \\mathbb{E}_{u(x)} \\left\\lbrack \\frac{|f(x)-g(x)|^p}{u(x)} \\right\\rbrack\\\\\n&\\approx \\frac{1}{N} \\sum_{n=1}^N \\frac{|f(x)-g(x)|^p}{u(x)} \\,\\,\\textrm{for}\\,\\, x_n \\overset{iid}{\\sim} u(x),\n\\end{aligned}\n\\] where the last term gets better approximation as \\(N\\rightarrow \\infty\\).\n\n\nReferences\n\n\nMarron, James Stephen, and I. L. Dryden. 2021. Object Oriented Data Analysis. Boca Raton: Taylor & Francis Group, LLC."
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "Riemann\nLearning with Data on Riemannian manifold\n\n        \n        Website\n      \n        \n        View on Github\n      \n        \n        View on CRAN\n    \nRiemBase\nFunctions and C++ Headers for Computation on Manifolds\n\n        \n        View on Github\n      \n        \n        View on CRAN\n    \nTDAkit\nToolkit for Topological Data Analysis\n\n        \n        View on Github\n      \n        \n        View on CRAN\n    \nNetwork\ngraphon\nA Collection of Graphon Estimation Methods\n\n        \n        View on Github\n      \n        \n        View on CRAN\n    \nNetworkDistance\nDistance Measures for Networks\n\n        \n        View on Github\n      \n        \n        View on CRAN\n    \nStatistical Inference\nCovTools\nStatistical Tools for Covariance Analysis\n\n        \n        View on Github\n      \n        \n        View on CRAN\n    \nfilling\nMatrix Completion, Imputation, and Inpainting Methods\n\n        \n        View on Github\n      \n        \n        View on CRAN\n    \nRdimtools\nDimension Reduction and Estimation Methods\n\n        \n        Website\n      \n        \n        View on Github\n      \n        \n        View on CRAN\n    \nSBmedian\nScalable Bayes with Median of Subset Posteriors\n\n        \n        View on Github\n      \n        \n        View on CRAN\n    \nSHT\nStatistical Hypothesis Testing Toolbox\n\n        \n        Website\n      \n        \n        View on Github\n      \n        \n        View on CRAN\n    \nT4cluster\nTools for Cluster Analysis\n\n        \n        Website\n      \n        \n        View on Github\n      \n        \n        View on CRAN\n    \nOptimization and Applied Mathematics\nmaotai\nTools for Matrix Algebra, Optimization and Inference\n\n        \n        Website\n      \n        \n        View on Github\n      \n        \n        View on CRAN\n    \nRlinsolve\nIterative Solvers for (Sparse) Linear System of Equations\n\n        \n        View on Github\n      \n        \n        View on CRAN\n    \nT4transport\nTools for Computational Optimal Transport\n\n        \n        Website\n      \n        \n        View on Github\n      \n        \n        View on CRAN\n    \ntvR\nTotal Variation Regularization for Signals and Images\n\n        \n        View on Github\n      \n        \n        View on CRAN"
  }
]